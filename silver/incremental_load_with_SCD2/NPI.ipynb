{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afc97e1c-9029-4664-820a-2f63ac94d61f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# service principal for integrating with ADLS and access it's data\n",
    "\n",
    "spark.conf.set(\"fs.azure.account.auth.type.hpadlsacc.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(\"fs.azure.account.oauth.provider.type.hpadlsacc.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.id.hpadlsacc.dfs.core.windows.net\", dbutils.secrets.get(\"hc-secret-scope\", \"app-key\"))\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.secret.hpadlsacc.dfs.core.windows.net\", dbutils.secrets.get(\"hc-secret-scope\", \"service-cred\"))\n",
    "tenant_id = dbutils.secrets.get(\"hc-secret-scope\", \"dir-id\")\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.endpoint.hpadlsacc.dfs.core.windows.net\", f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "adec3d55-b45e-4c61-a16b-07e1c3f4b053",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Creating the NPI table in Silver layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef22aae8-e35e-4c15-aa90-bf66a544bda9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# defining the source path for NPI\n",
    "src_npi = \"abfss://bronze@hpadlsacc.dfs.core.windows.net/npi_extract\"\n",
    "\n",
    "# reading the path data\n",
    "df=spark.read.parquet(src_npi)\n",
    "df.display()\n",
    "\n",
    "# creating a temp view\n",
    "df.createOrReplaceTempView('npi_extract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cd158eb-9050-4ce0-9380-7044afcb148d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- creating a silver.npi_extract external table \n",
    "\n",
    "CREATE TABLE IF NOT EXISTS silver.npi_extract (\n",
    "  npi_id STRING,\n",
    "  first_name STRING,\n",
    "  last_name STRING,\n",
    "  position STRING,\n",
    "  organisation_name STRING,\n",
    "  last_updated STRING,\n",
    "  inserted_date DATE,\n",
    "  updated_date DATE,\n",
    "  is_current_flag BOOLEAN\n",
    ")\n",
    "USING DELTA\n",
    "LOCATION \"abfss://silver@hpadlsacc.dfs.core.windows.net/NPI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "409b5949-ddf6-461b-9e87-ca855805701d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Step 1: based on condition npi_id should be simliar and is_current should be true (i.e currently that specific record is active)\n",
    "-- Mark that existing records as historical (is_current = false) for patients that will be updated\n",
    "-- target.is_current = false,\n",
    "-- target.modified_date = current_timestamp()\n",
    "\n",
    "\n",
    "MERGE INTO\n",
    "  silver.npi_extract AS target\n",
    "USING\n",
    "  npi_extract AS source\n",
    "ON target.npi_id = source.npi_id and target.is_current_flag = true\n",
    "WHEN MATCHED AND\n",
    "  target.first_name != source.first_name OR\n",
    "  target.last_name != source.last_name OR\n",
    "  target.position != source.position OR\n",
    "  target.organisation_name != source.organisation_name OR\n",
    "  target.last_updated != source.last_updated\n",
    "  THEN UPDATE SET\n",
    "  target.updated_date = current_date,\n",
    "  target.is_current_flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "467f03eb-c190-4dc4-a67a-d2062d2b1941",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Step 2: Insert new and updated records into the Delta table, marking them as current\n",
    "-- that is old record is updated with new records\n",
    "-- based on condition npi_id should be simliar and is_current should be true (i.e currently that specific record is active)\n",
    "-- because the condition will not satisfy\n",
    "-- inserting the new records which are not present in the silver table and updating the old records\n",
    "\n",
    "MERGE INTO\n",
    "  silver.npi_extract AS target\n",
    "USING\n",
    "  npi_extract AS source\n",
    "ON target.npi_id = source.npi_id and target.is_current_flag = true\n",
    "WHEN NOT MATCHED THEN INSERT (\n",
    "   npi_id,\n",
    "  first_name ,\n",
    "  last_name ,\n",
    "  position ,\n",
    "  organisation_name ,\n",
    "  last_updated ,\n",
    "  inserted_date ,\n",
    "  updated_date ,\n",
    "  is_current_flag \n",
    ")\n",
    "  VALUES (\n",
    "    source.npi_id,\n",
    "  source.first_name ,\n",
    "  source.last_name ,\n",
    "  source.position ,\n",
    "  source.organisation_name ,\n",
    "  source.last_updated ,\n",
    "  current_date,\n",
    "  current_date, \n",
    "  true\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "846809eb-5192-46d8-8b85-75abc9e0f081",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- displaying some records\n",
    "\n",
    "select * from silver.npi_extract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63571daa-8514-4031-8c66-3bb835729efd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- drop table silver.npi_extract"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6342263754267271,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "NPI",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
